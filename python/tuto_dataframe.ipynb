{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478e9cb0",
   "metadata": {},
   "source": [
    "# Traiter la donnée -- Dataframes\n",
    "\n",
    "\n",
    "Pour le réaliser sans installation, depuis un navigateur :\n",
    "<a href=\"https://colab.research.google.com/github/eddes/INSA/blob/main/python/tuto_dataframe.ipynb\"> ça se passe ici<a>\n",
    "\n",
    "\n",
    "Dans de nombreux des domaines, la donnée disponible est fournie dans des fichiers texte, où les valeurs des différentes grandeurs sont séparées par des virgules (vos tableurs favoris exportent parfois en `.csv` - acronyme de _comma separated values_).\n",
    "    \n",
    "Une librairie particulièrement bien adaptée au traitement de tels fichiers est `pandas`. Dans ce qui suit, nous allons eb apprendre les bases.\n",
    "    \n",
    "## Ouverture et affichage de base\n",
    "\n",
    "Ouvrons un des fichiers de données météorologiques mesurées près de la ville de Strasbourg en 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d6bea42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chemin='./src/meteo_Strasbourg_2023.csv'\n",
    "donnee = pd.read_csv(chemin, index_col=0) # on precise d'ores et deja que l'index est en colonne \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bbc40",
   "metadata": {},
   "source": [
    "Pour afficher quelques stats de base sur les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dea4a5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "      <th>coco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>1848.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1848.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.921916</td>\n",
       "      <td>10.926840</td>\n",
       "      <td>59.792208</td>\n",
       "      <td>0.052489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.846861</td>\n",
       "      <td>11.822294</td>\n",
       "      <td>21.776136</td>\n",
       "      <td>1016.550866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.145563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.818102</td>\n",
       "      <td>3.669961</td>\n",
       "      <td>19.372118</td>\n",
       "      <td>0.420076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.132250</td>\n",
       "      <td>6.827365</td>\n",
       "      <td>9.394996</td>\n",
       "      <td>3.602004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.867574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1007.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.575000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>1014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.200000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>1016.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.500000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>27.800000</td>\n",
       "      <td>1018.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1026.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              temp         dwpt         rhum         prcp   snow         wdir  \\\n",
       "count  1848.000000  1848.000000  1848.000000  1848.000000  608.0  1848.000000   \n",
       "mean     19.921916    10.926840    59.792208     0.052489    0.0   170.846861   \n",
       "std       5.818102     3.669961    19.372118     0.420076    0.0   129.132250   \n",
       "min       4.500000     2.100000    21.000000     0.000000    0.0     0.000000   \n",
       "25%      15.575000     8.500000    44.000000     0.000000    0.0    30.000000   \n",
       "50%      19.200000    10.500000    60.000000     0.000000    0.0   180.000000   \n",
       "75%      24.500000    13.600000    75.000000     0.000000    0.0   300.000000   \n",
       "max      36.000000    21.000000   100.000000     9.000000    0.0   360.000000   \n",
       "\n",
       "              wspd         wpgt         pres  tsun         coco  \n",
       "count  1848.000000  1848.000000  1848.000000   0.0  1848.000000  \n",
       "mean     11.822294    21.776136  1016.550866   NaN     4.145563  \n",
       "std       6.827365     9.394996     3.602004   NaN     2.867574  \n",
       "min       0.000000     3.700000  1007.700000   NaN     1.000000  \n",
       "25%       6.000000    14.800000  1014.000000   NaN     4.000000  \n",
       "50%      11.000000    20.400000  1016.300000   NaN     4.000000  \n",
       "75%      16.600000    27.800000  1018.700000   NaN     4.000000  \n",
       "max      35.300000    57.000000  1026.100000   NaN    25.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnee.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dff56d",
   "metadata": {},
   "source": [
    "On peut donc, pour chaque colonne, lire les min/max ainsi que les percentiles de la série.\n",
    "\n",
    "Ensuite, il est pratique de connaître le nom des données stockées, pour pouvoir les appeler séparément :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a989f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres',\n",
       "       'tsun', 'coco'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnee.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e6f93",
   "metadata": {},
   "source": [
    "On constate que le temps `time` et la température `temp` sont stockées. On va pouvoir y faire appel simplement par leur nom avec une commande du style :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b85b148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-05-01 00:00:00    10.3\n",
       "2023-05-01 01:00:00     9.8\n",
       "2023-05-01 02:00:00     9.8\n",
       "2023-05-01 03:00:00     9.8\n",
       "2023-05-01 04:00:00    10.0\n",
       "                       ... \n",
       "2023-07-16 19:00:00    21.0\n",
       "2023-07-16 20:00:00    20.0\n",
       "2023-07-16 21:00:00    19.6\n",
       "2023-07-16 22:00:00    18.0\n",
       "2023-07-16 23:00:00    17.0\n",
       "Name: temp, Length: 1848, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donnee['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333f7af",
   "metadata": {},
   "source": [
    "On notera la présence d'un index (colonne de gauche qui est affichée). Cet index est commun à toutes les données stockées, lorsqu'il y en a plusieurs. Il peut aussi être un temps (heure/min/sec j/m/a) ce qui se révèlera particulièrement pratique par la suite.\n",
    "\n",
    "Si on souhaite uniquement en prendre les valeurs on utilise le suffixe `values` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "690f77f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.3  9.8  9.8 ... 19.6 18.  17. ]\n"
     ]
    }
   ],
   "source": [
    "T = donnee['temp'].values\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b813e03",
   "metadata": {},
   "source": [
    "## Sélection de données avec pandas\n",
    "\n",
    "Il est parfois pratique de connaître/isoler rapidement les valeurs en-dessous ou au-dessus d'un certain seuil. Supposons qu'on veuille connaitre les instants où la température est supérieure à 26°C :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1786ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  \\\n",
      "time                                                                           \n",
      "2023-05-21 15:00:00  26.5  14.3  47.0   0.0   0.0   20.0  16.6  41.0  1010.7   \n",
      "2023-05-21 16:00:00  26.4  13.9  46.0   0.0   NaN   20.0  18.4  25.9  1011.0   \n",
      "2023-05-22 11:00:00  26.3  15.4  51.0   0.0   NaN   40.0   9.4  20.4  1012.5   \n",
      "2023-05-22 12:00:00  27.2  15.2  48.0   0.0   0.0  120.0   3.6  24.0  1012.5   \n",
      "2023-05-22 13:00:00  26.8  15.5  50.0   0.0   NaN  280.0  13.0  24.1  1012.1   \n",
      "...                   ...   ...   ...   ...   ...    ...   ...   ...     ...   \n",
      "2023-07-15 14:00:00  30.0  17.1  46.0   0.0   NaN  170.0  15.0  29.6  1010.0   \n",
      "2023-07-15 15:00:00  30.6  19.9  53.0   0.0   0.0   20.0  15.0  31.0  1008.6   \n",
      "2023-07-15 16:00:00  29.0  19.0  55.0   0.0   NaN  360.0  19.0  40.8  1009.0   \n",
      "2023-07-15 17:00:00  29.0  19.0  55.0   0.0   NaN   10.0  20.0  33.3  1009.0   \n",
      "2023-07-15 18:00:00  26.3  18.4  62.0   0.0   0.0  350.0  26.0  37.0  1008.9   \n",
      "\n",
      "                     tsun  coco  \n",
      "time                             \n",
      "2023-05-21 15:00:00   NaN   3.0  \n",
      "2023-05-21 16:00:00   NaN   3.0  \n",
      "2023-05-22 11:00:00   NaN   4.0  \n",
      "2023-05-22 12:00:00   NaN   4.0  \n",
      "2023-05-22 13:00:00   NaN   4.0  \n",
      "...                   ...   ...  \n",
      "2023-07-15 14:00:00   NaN   4.0  \n",
      "2023-07-15 15:00:00   NaN  18.0  \n",
      "2023-07-15 16:00:00   NaN  25.0  \n",
      "2023-07-15 17:00:00   NaN  25.0  \n",
      "2023-07-15 18:00:00   NaN  25.0  \n",
      "\n",
      "[309 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "fait_chaud = donnee[ donnee['temp'] > 26]\n",
    "print(fait_chaud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9241e",
   "metadata": {},
   "source": [
    "Il y a donc 309 valeurs avec une température supérieure à 26.\n",
    "\n",
    "Pour pouvoir identifier s'il s'agit du jour ou de la nuit, on peut utiliser la colonne `time` en s'assurant de convertir l'index en un format permettant de gérer les opérations sur le temps (un horodatage en quelque sorte - voir plus bas les différentes techniques pour permettre la reconnaissance de l'horodatage des données lors de la lecture du `.csv`) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f6e6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-05-01 00:00:00', '2023-05-01 01:00:00',\n",
      "               '2023-05-01 02:00:00', '2023-05-01 03:00:00',\n",
      "               '2023-05-01 04:00:00', '2023-05-01 05:00:00',\n",
      "               '2023-05-01 06:00:00', '2023-05-01 07:00:00',\n",
      "               '2023-05-01 08:00:00', '2023-05-01 09:00:00',\n",
      "               ...\n",
      "               '2023-07-16 14:00:00', '2023-07-16 15:00:00',\n",
      "               '2023-07-16 16:00:00', '2023-07-16 17:00:00',\n",
      "               '2023-07-16 18:00:00', '2023-07-16 19:00:00',\n",
      "               '2023-07-16 20:00:00', '2023-07-16 21:00:00',\n",
      "               '2023-07-16 22:00:00', '2023-07-16 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='time', length=1848, freq=None)\n"
     ]
    }
   ],
   "source": [
    "donnee.index = pd.to_datetime(donnee.index) # ici on convertit l'index en datetime\n",
    "print(donnee.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954d1b2",
   "metadata": {},
   "source": [
    "On constate que le format de donnée de l'index `dtype` correspond désormais à un `datetime`. Ceci va nous faciliter la tâche pour trier la donnée. Si l'on souhaite connaître les moments de l'année 2023 où il a fait plus de 22°C après 21h à Strasbourg, on peut filtrer la donnée comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c35a2afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  \\\n",
      "time                                                                           \n",
      "2023-05-01 23:00:00  11.8   8.1  78.0   0.0   NaN  310.0   7.6  11.1  1018.9   \n",
      "2023-05-02 23:00:00  10.8   5.1  68.0   0.0   NaN   30.0  22.3  16.7  1025.8   \n",
      "2023-05-03 23:00:00  11.4   5.9  69.0   0.0   NaN   20.0   9.4   9.3  1021.3   \n",
      "2023-05-04 23:00:00  15.7  12.1  79.0   0.0   NaN  250.0   5.4  11.1  1017.7   \n",
      "2023-05-05 23:00:00  13.7  13.1  96.0   0.0   NaN  290.0   5.4  20.4  1018.5   \n",
      "...                   ...   ...   ...   ...   ...    ...   ...   ...     ...   \n",
      "2023-07-12 23:00:00  17.0  11.9  72.0   0.0   NaN  280.0  11.0  13.0  1017.0   \n",
      "2023-07-13 23:00:00  16.0  11.0  72.0   0.0   NaN  257.0   4.0   9.3  1019.0   \n",
      "2023-07-14 23:00:00  19.0  15.1  78.0   0.0   NaN  360.0   6.0  11.1  1011.0   \n",
      "2023-07-15 23:00:00  19.0  18.0  94.0   2.2   NaN  140.0   7.0  29.6  1015.0   \n",
      "2023-07-16 23:00:00  17.0  12.9  77.0   0.0   NaN  200.0   9.0  14.8  1019.0   \n",
      "\n",
      "                     tsun  coco  \n",
      "time                             \n",
      "2023-05-01 23:00:00   NaN   4.0  \n",
      "2023-05-02 23:00:00   NaN   4.0  \n",
      "2023-05-03 23:00:00   NaN   1.0  \n",
      "2023-05-04 23:00:00   NaN   4.0  \n",
      "2023-05-05 23:00:00   NaN   4.0  \n",
      "...                   ...   ...  \n",
      "2023-07-12 23:00:00   NaN   4.0  \n",
      "2023-07-13 23:00:00   NaN   4.0  \n",
      "2023-07-14 23:00:00   NaN   4.0  \n",
      "2023-07-15 23:00:00   NaN   9.0  \n",
      "2023-07-16 23:00:00   NaN   4.0  \n",
      "\n",
      "[77 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "nuit_chaud = donnee[ (donnee.index.hour > 21) & (donnee['temp']>22) ]\n",
    "print(df_chaud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c5b5e",
   "metadata": {},
   "source": [
    "###  Fusion de deux dataframe en conservant l'index, les valeurs et en interpolant sur les NaN\n",
    "\n",
    "Oui, c'est possible et c'est même très pratique : par exemple quand on récupère des données mesurées et qu'on souhaite y adjoindre une mesure sur un autre pas de temps. Un exemple typique est le cas de mesures dans un bâtiment et de la température extérieure, récupérée par exemple avec <a href=\"https://colab.research.google.com/github/eddes/INSA/blob/main/python/tuto_meteostat.ipynb\"> Meteostat<a>.\n",
    "    \n",
    "L'exemple qui suit traite de ce cas pratique, avec un fichier **meteo.csv** qui contient des mesures à heures fixes et un fixer **mesure.csv** qui contient des mesures toutes les 15 minutes, sans être calé sur une heure \"pile\" (ouvrir le fichier pour mieux saisir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92c45872",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './src/meteo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# lecture du fichier meteo\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df_meteo \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./src/meteo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m,delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquoi dedans ? \u001b[39m\u001b[38;5;124m'\u001b[39m, df_meteo\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# on nettoie car seule la premiere colonne 'temp' nous interesse et on ne souhaite pas realiser l'interpolation sur toutes les colonnes\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 'temp' est la grandeur qui nous interesse, c'est la premiere colonne\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# on cree donc une liste des colonnes qui vont etre supprimées\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './src/meteo.csv'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# lecture du fichier meteo\n",
    "df_meteo = pd.read_csv('./src/meteo.csv', index_col=0, header=\"infer\",delimiter=',')\n",
    "print('quoi dedans ? ', df_meteo.keys())\n",
    "\n",
    "# on nettoie car seule la premiere colonne 'temp' nous interesse et on ne souhaite pas realiser l'interpolation sur toutes les colonnes\n",
    "# 'temp' est la grandeur qui nous interesse, c'est la premiere colonne\n",
    "# on cree donc une liste des colonnes qui vont etre supprimées\n",
    "cols = range(1, len(df_meteo .keys() ))  \n",
    "# c'est parti : noter la syntaxe df.drop()\n",
    "df_meteo.drop(df_meteo .columns[cols], axis=1, inplace=True) \n",
    "\n",
    "# on lit les donnees mesurees\n",
    "df_mesure = pd.read_csv('./src/mesure.csv', index_col=0, header=\"infer\",delimiter=',')\n",
    "\n",
    "# on va fusionner les deux et surtout les reclasser par index, sinon pas d'interpolation\n",
    "df_concat = pd.concat([df_mesure,df_meteo]).sort_index()\n",
    "\n",
    "# puis on interpole lineairement sur les donnees disponibles (il y a plusieurs methodes d'interpolation)\n",
    "df_interp = df_concat.interpolate(method='linear')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(df_meteo['temp'],'k-o', label='original')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(df_interp['temp'], 'k--.', label='interpole')\n",
    "plt.legend()\n",
    "\n",
    "# au besoin on sauve pour regarder ce qu'il y a dedans\n",
    "# df_interp.to_csv('./data_interp.csv')\n",
    "# df_concat.to_csv('./data_concat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdcc9d1",
   "metadata": {},
   "source": [
    "## Cheat cheat dataframe\n",
    "\n",
    "Quelques bouts de code utiles...\n",
    "\n",
    "### Convertir un index de .csv en datetime\n",
    "\n",
    "#### Plan A\n",
    "\n",
    "Si le format de date est classique YYYY-MM-DD HH:MM:SS\n",
    "\n",
    "`donnee.index = pd.to_datetime(donnee.index)`\n",
    "\n",
    "Si le format de date n'est pas reconnu\n",
    "\n",
    "`donnee.index = pd.to_datetime(donnee.index, format='%Y-%m-%d %H:%M:%S')`\n",
    "\n",
    "#### Plan B - avec dates \"à la française\" \n",
    "\n",
    "Dans ce cas le jour apparaît en premier, puis le mois, puis l'année:\n",
    "`df.index = pd.to_datetime(df.index, dayfirst=True)`\n",
    "\n",
    "#### Plan C\n",
    "\n",
    "En comptant sur la chance, on demande à pandas de trouver le format de date pour nous\n",
    "\n",
    "`dossier='./src/'`\n",
    "\n",
    "`nom='data.csv`\n",
    "\n",
    "`df= pd.read_csv(dossier+nom, index_col=0, parse_dates=[0])`\n",
    "\n",
    "### Suppression de valeurs\n",
    "\n",
    "#### Les doublons\n",
    "\n",
    "On supprime par index :\n",
    "`df.drop_duplicates(inplace=True)`\n",
    "\n",
    "#### Les colonnes\n",
    "\n",
    "Il faut définir la liste `cols` ou l'entier `cols` au préalable (identifier les indices des colonnes que l'on souhaite supprimer)\n",
    "\n",
    "`df.drop( df.columns[cols], axis=1, inplace=True)`\n",
    "\n",
    "#### Arrondir à deux décimales\n",
    "\n",
    "`df = df.round({'temperature':2})`\n",
    "\n",
    "#### Remplacer des valeurs non souhaitées\n",
    "\n",
    "Par exemple lorsqu'un capteur renvoie trois tirets quand il ne capte plus :\n",
    "\n",
    "`df['Tair'] = df['Tair'].replace('---', np.nan)`\n",
    "\n",
    "Ou lorsqu'une case est vide (parfois pratique de remplacer par __not a number__ - np.nan)\n",
    "\n",
    "`df['Tair'] = df['Tair'].replace([None], np.nan) `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17191caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48242440",
   "metadata": {},
   "outputs": [],
   "source": ["Beaucoup plus chez https://matbog.github.io/code"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
